
 <!DOCTYPE HTML>
<html >
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  
    <title>TensorFlow个人使用教程 | LI jianan&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, minimum-scale=1">
    
    <meta name="author" content="LI jianan">
    
    <meta name="description" content="大致想到这几个部分，第一块是像是checkpoint一类的固定流程；还有一块是像是tf.train.shuffle_batch和tf.train.string_input_producer的能够逐行读取的语句。下面每一节是一个点，逻辑性可能不强。                           ">
    
    
    
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/myLogo.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/myLogo.jpg">
    

  
  

    <link rel="stylesheet" href="/css/style.css">
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?d182ed77fc48758bf45a33835ee35745";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

      <script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v1/st.js','_st');

  _st('install','.............Add your swiftype userID...............');
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

  <body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><header>
      <div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="LI jianan&#39;s Blog">LI jianan&#39;s Blog</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
                    <ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
					<li>
					
					</li>
                <!--<li><div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div></li>-->

				</ul>
			</nav>	
</div>
    </header>
    <div id="container" class="clearfix">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/07/18/tensorflow/" title="TensorFlow个人使用教程" itemprop="url">TensorFlow个人使用教程</a>
  </h1>
  <p class="article-time">
    <time datetime="2018-07-18T10:41:44.000Z" itemprop="datePublished">2018-07-18</time>
  </p>
</header>
	<div class="article-content">
		
		
		<p>大致想到这几个部分，第一块是像是checkpoint一类的固定流程；还有一块是像是tf.train.shuffle_batch和tf.train.string_input_producer的能够逐行读取的语句。下面每一节是一个点，逻辑性可能不强。                                                                                                                                                                                                                                                                                                                 </p>
<h1 id="1-基本用法"><a href="#1-基本用法" class="headerlink" title="1. 基本用法"></a>1. 基本用法</h1><p><strong>•使用图 (graph) 来表示计算任务；<br>•在被称之为 会话 (Session) 的上下文 (context) 中执行图；<br>•使用 tensor 表示数据；<br>•通过 变量 (Variable) 维护状态；<br>•使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据。</strong><br>Fetch指的是为了取回操作的输出内容，可以在使用 Session 对象的 run() 调用 执行图时，传入一些 tensor, 这些 tensor 会帮助你取回结果。</p>
<h1 id="2-tf-train-string-input-producer"><a href="#2-tf-train-string-input-producer" class="headerlink" title="2. tf.train.string_input_producer()"></a>2. tf.train.string_input_producer()</h1><p>当处理图片数据是类似以txt文件形式存储，每一行表示一个样本，有多少行就有多少样本，这时可以用<strong>tf.train.string_input_producer</strong>来处理<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">input_queue = tf.train.string_input_producer([filenames_file], shuffle=<span class="keyword">False</span>)</span><br><span class="line">line_reader = tf.TextLineReader()</span><br><span class="line">_, line = line_reader.read(input_queue) <span class="comment"># _ represent key</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tf.train.string_input_producer(</span><br><span class="line">    string_tensor,</span><br><span class="line">    num_epochs=None,</span><br><span class="line">    shuffle=True,</span><br><span class="line">    seed=None,</span><br><span class="line">    capacity=32,</span><br><span class="line">    shared_name=None,</span><br><span class="line">    name=None,</span><br><span class="line">    cancel_op=None</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>•string_tensor: A 1-D string tensor with the strings to produce.<br>•num_epochs: An integer (optional). If specified, string_input_producer produces each string from string_tensor num_epochs times before generating an OutOfRange error. If not specified, string_input_producer can cycle through the strings in string_tensor an unlimited number of times.<br>•shuffle: Boolean. If true, the strings are randomly shuffled within each epoch.<br>•seed: An integer (optional). Seed used if shuffle == True.</strong></p>
<h1 id="3-tf-train-shuffle-batch"><a href="#3-tf-train-shuffle-batch" class="headerlink" title="3. tf.train.shuffle_batch()"></a>3. tf.train.shuffle_batch()</h1><p>上面的代码过后，我们可以对读取出来的一行进行操作，而TF会自动跳转到下一行。例如当上面的一行表示左右两张图片时，进行如下操作：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">split_line = tf.string_split([line]).values</span><br><span class="line"></span><br><span class="line"><span class="comment"># we load only one image for test, except if we trained a stereomodel</span></span><br><span class="line"><span class="keyword">if</span> self.mode == <span class="string">'test'</span> <span class="keyword">and</span> <span class="keyword">not</span> self.params.do_stereo:</span><br><span class="line">	eft_image_path = tf.string_join([self.data_path, split_line[<span class="number">0</span>]])</span><br><span class="line">	left_image_o = self.read_image(left_image_path)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">	left_image_path = tf.string_join([self.data_path, split_line[<span class="number">0</span>]])</span><br><span class="line">	right_image_path = tf.string_join([self.data_path, split_line[<span class="number">1</span>]])</span><br><span class="line">	left_image_o = self.read_image(left_image_path)</span><br><span class="line">	right_image_o = self.read_image(right_image_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> self.mode == <span class="string">'train'</span>:</span><br><span class="line">	<span class="comment"># randomly filp image</span></span><br><span class="line">	do_flip = tf.random_uniform([], <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">	left_image = tf.cond(do_flip &gt; <span class="number">0.5</span>, <span class="keyword">lambda</span>: tf.filp_left_right(right_image_o), <span class="keyword">lambda</span>: left_image_o)</span><br><span class="line">	right_image = tf.cond(do_flip &gt; <span class="number">0.5</span>, <span class="keyword">lambda</span>: tf.filp_left_right(left_image_o), <span class="keyword">lambda</span>: right_image_o)</span><br><span class="line"></span><br><span class="line">	<span class="comment"># randomly augment images</span></span><br><span class="line">	do_augment = tf.random_uniform([], <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">	left_image, right_image = tf.cond(do_augment &gt; <span class="number">0.5</span>, <span class="keyword">lambda</span>: self.augment_image_pair(left_image, right_image), <span class="keyword">lambda</span>: (left_image, right_image))</span><br><span class="line"></span><br><span class="line">	left_image.set_shape([<span class="keyword">None</span>, <span class="keyword">None</span>, <span class="number">3</span>])</span><br><span class="line">	right_image.set_shape([<span class="keyword">None</span>, <span class="keyword">None</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure></p>
<p>顺便提一下，<strong>tensor.set_shape()用在这里是因为读入图片之后计算机还不知道channels数是多少，我们可以人工为此提供额外的信息。如果我们可以确定训练用的图片的大小，也可以吧height和width填上。</strong></p>
<p>那么由string_input_producer提取出来的数据经过上述处理之后，<strong>我们想要生成一个一个num_batch可以这样操作：</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># capacity = min_after_dequeue + (num_threads + a small safety margin) * batch_size</span></span><br><span class="line">min_after_dequeue = <span class="number">2048</span></span><br><span class="line">capacity = min_after_dequeue + (self.params.num_threads + <span class="number">0.5</span>) * self.params.batch_size</span><br><span class="line">self.left_image_batch, self.right_image_batch = tf.train.shuffle_batch([left_image, right_image], </span><br><span class="line">	self.params.batch_size, capacity, min_after_dequeue, self.params.num_threads)</span><br></pre></td></tr></table></figure></p>
<p><strong>•min_after_dequeue: Minimum number elements in the queue after a dequeue, used to ensure a level of mixing of elements.<br>•num_threads: The number of threads enqueuing tensor_list.</strong></p>
<h1 id="4-基本流程"><a href="#4-基本流程" class="headerlink" title="4. 基本流程"></a>4. 基本流程</h1><p>训练开始，先定义一个图，因为一开始是些常规动作，不涉及模型可以先用CPU来跑：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default(), tf.device(<span class="string">'/cpu:0'</span>):</span><br></pre></td></tr></table></figure></p>
<p>一些常规动作之后，在开始建立模型和计算Loss之前：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(tf.get_variable_scope()):</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(params.num_gpus):</span><br><span class="line">                <span class="keyword">with</span> tf.device(<span class="string">'/gpu:%d'</span> % i):</span><br></pre></td></tr></table></figure></p>
<p>接下来介绍<strong>tf.summary.scalar()</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.summary.scalar(<span class="string">'learning_rate'</span>, learning_rate, [<span class="string">'model_0'</span>])</span><br><span class="line">tf.summary.scalar(<span class="string">'total_loss'</span>, total_loss, [<span class="string">'model_0'</span>])</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tf.summary.scalar(</span><br><span class="line">    name,</span><br><span class="line">    tensor,</span><br><span class="line">    collections=<span class="keyword">None</span>,</span><br><span class="line">    family=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>作用：输出一个包含单个标量值的summary协议缓冲区。<br>参数：<br>    name：string/Tensor，字符串或已经创建的表示summary的Tensor，为summary的名称(标签), 也是此Op的名称；<br>    tensor：Tensor, 要记录的包含单个标量值的Tensor；<br>    collections：将此Op添加到图中collection指定的key值中。<br>输出: Tensor，类型为string，包含summary协议缓冲区的信息。</strong></p>
<p>还有<strong>tf.summary.image()</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.summary.image(</span><br><span class="line">    name,</span><br><span class="line">    tensor,</span><br><span class="line">    max_outputs=<span class="number">3</span>,</span><br><span class="line">    collections=<span class="keyword">None</span>,</span><br><span class="line">    family=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p><strong>作用：输出一个包含图像的summary协议缓冲区。<br>参数：<br>    name：string/Tensor, 字符串或已经创建的表示summary的Tensor，为summary的名称(标签)，也是此Op的名称；<br>    tensor：要记录的图像Tensor，格式必须为4-D的uint8或float32，<br>            shape中元素意义为[batch_size, height, width, channels]，<br>            channels的值为{1: 灰度图, 3: RGB图, 4: RGBA图}；<br>    max_outputs：最多只能生成3张图片的summary；<br>    collections：将此Op添加到图中collection指定的key值中。<br>输出：Tensor，类型为string，包含summary协议缓冲区的信息。</strong></p>
<p>然后<strong>tf.summary.merge_al()</strong>:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.summary.merge_all(</span><br><span class="line">    key=tf.GraphKeys.SUMMARIES,</span><br><span class="line">    scope=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p><strong>作用：收集合并默认图中所有的summary。<br>参数：<br>    key：’GraphKey’，用来收集summary；默认为_ops.GraphKeys.SUMMARIES<br>输出：如果没有创建summary，结果为空，否则返回一个dtype为string的Tensor，内容是序列化的字符串，包含merge合并后的Summary protocol buffer。</strong></p>
<p><strong>tf.summary.FileWriter()</strong><br>FileWriter是一个Class<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">__init__(</span><br><span class="line">    logdir,</span><br><span class="line">    graph=<span class="keyword">None</span>,</span><br><span class="line">    max_queue=<span class="number">10</span>,</span><br><span class="line">    flush_secs=<span class="number">120</span>,</span><br><span class="line">    graph_def=<span class="keyword">None</span>,</span><br><span class="line">    filename_suffix=<span class="keyword">None</span>,</span><br><span class="line">    session=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p><strong>作用: 将图的汇总信息写入到磁盘的类, 写入磁盘的方式为异步, 因此不会降低训练的速度.<br>参数:<br>    logdir: (must)事件写入的文件位置;<br>    graph: 写入对应的Graph类, 一般使用’sess.graph’获取会话Session对应的图;</strong><br>    max_queue: 整数, 待写入的队列大小;<br>    flush_secs: 将事件刷新到磁盘的时间间隔;<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">summary_writer = tf.summary.FileWriter(arg.log_directory + <span class="string">'/'</span> + args.model_name, sess.graph)</span><br></pre></td></tr></table></figure></p>
  
	</div>
		<footer class="article-footer clearfix">

  <div class="article-tags">
  
  <span></span> <a href="/tags/TensorFlow/">TensorFlow</a>
  </div>




<div class="article-share" id="share">

  <div data-url="https://www.lijn.tech/2018/07/18/tensorflow/" data-title="TensorFlow个人使用教程 | LI jianan&#39;s Blog" data-tsina="" class="share clearfix">
  </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2018/07/19/basicc/" title="C++编程基础">
  <strong>Previous:</strong><br/>
  <span>
  C++编程基础</span>
</a>
</div>


<div class="next">
<a href="/2018/07/13/rnn/"  title="Recurrent Neural Networks">
 <strong>Next:</strong><br/> 
 <span>Recurrent Neural Networks
</span>
</a>
</div>

</nav>

	

</div>  
    </div>
    <footer><div id="footer" >
	<div class="copyright">
		<span> If you are interested in Computer Vision, you can contact </span>
			<span> <a href="https://github.com/JnanLi">me.</a> </span>
	<div>
</div></footer>
    <script src="/js/jquery-2.1.0.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  //back to top
  function backToTop(){
    var buttonHTML = $("<a href=\"#top\" id=\"back-top\">" + "<span>Back to Top</span></a>");
    buttonHTML.appendTo($("body"));
    var buttonToTop = $("#back-top");
    // hide #back-top first
    buttonToTop.hide();

    // fade in #back-top
    $(function() {
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                buttonToTop.fadeIn();
            } else {
                buttonToTop.fadeOut();
            }
        });
        // scroll body to 0px on click
        buttonToTop.click(function() {
            $('body,html').animate({
                scrollTop: 0
            }, 800);
            return false;
        });
    });
  }
  backToTop();

  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      ta = $('#toc.toc-aside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
        
    }
  });

  var show = true;
  c.click(function(){
    if(show == true){
        a.addClass('fadeOut').css('display', 'none');
        ta.css('display', 'block').addClass('fadeIn');
        m.addClass('moveMain');  
    }else{
        a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');     
        ta.css('display', 'none'); 
        m.removeClass('moveMain');
        $('#toc.toc-aside').css('display', 'none');
    }
    show = !show;
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{

    $(window).scroll(function(){
      ta.css("top",Math.max(140,240-$(this).scrollTop()));
    });
  };
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#share"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="#textlogo" class="article-back-to-top" title="Top"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="QRcode"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="Weibo"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>




<script type="text/javascript">
  function footerPosition() {
    var contentHeight = document.documentElement.scrollHeight,
        winHeight = window.innerHeight;
    if(contentHeight <= winHeight) {
      $('footer').addClass('fixed-bottom');
    } else {
      $('footer').removeClass('fixed-bottom');
    }
  }
  footerPosition();
  $(window).resize(footerPosition);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


  </body>
</html>
