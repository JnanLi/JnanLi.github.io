
 <!DOCTYPE HTML>
<html >
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
  
    <title>SLAM(Simultaneous localization and mapping) | LI jianan&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, minimum-scale=1">
    
    <meta name="author" content="LI jianan">
    
    <meta name="description" content="同步定位与地图构建是一种概念：希望机器人从未知环境的未知地点出发，在运动过程中通过重复观测到的地图特征（比如，墙角，柱子等）定位自身位置和姿态，再根据自身位置增量式的构建地图，从而达到同时定位和地图构建的目的。                                             ">
    
    
    
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/myLogo.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/myLogo.jpg">
    

  
  

    <link rel="stylesheet" href="/css/style.css">
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?d182ed77fc48758bf45a33835ee35745";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

      <script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v1/st.js','_st');

  _st('install','.............Add your swiftype userID...............');
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

  <body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><header>
      <div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="LI jianan&#39;s Blog">LI jianan&#39;s Blog</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
                    <ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
					<li>
					
					</li>
                <!--<li><div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div></li>-->

				</ul>
			</nav>	
</div>
    </header>
    <div id="container" class="clearfix">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/06/30/SLAM/" title="SLAM(Simultaneous localization and mapping)" itemprop="url">SLAM(Simultaneous localization and mapping)</a>
  </h1>
  <p class="article-time">
    <time datetime="2018-06-30T06:14:46.000Z" itemprop="datePublished">2018-06-30</time>
  </p>
</header>
	<div class="article-content">
		
		
		<p><strong>同步定位与地图构建</strong>是一种概念：希望机器人从未知环境的未知地点出发，在运动过程中通过重复观测到的地图特征（比如，墙角，柱子等）定位自身位置和姿态，再根据自身位置增量式的构建地图，从而达到同时定位和地图构建的目的。                                                                                                                                                                                                                                                                                          </p>
<h1 id="什么是SLAM？"><a href="#什么是SLAM？" class="headerlink" title="什么是SLAM？"></a>什么是SLAM？</h1><p>外行乍一听起来非常拗口，为了不在一开始就吓跑读者，我们先不对其进行专业的解释，用一个形象的例子来进行说明。我们知道现在有不少家用的扫地机器人（如下图所示），可以代替人对室内进行自动清扫。早期的扫地机器人并不智能，它只是具有简单的避障功能，在室内随机游走，遇到障碍物就转弯，这样会导致有很多地方会漏掉，扫地效率非常低。</p>
<p><img src="/2018/06/30/SLAM/saodi.webp" alt=""></p>
<p>要想真正实现智能的清扫，扫地机器人至少需要知道以下几件事情：</p>
<p>1、我在哪里？也就是扫地机器人在工作过程中要知道自己在房间的具体位置。对应的术语叫：<em>定位（Localization)</em>。</p>
<p>2、我周围的环境是什么样子？也就是扫地机器人需要知道整个房间的地面结构信息。对应的术语叫：<em>建图(Mapping)</em>。</p>
<p>3、我怎样到达指定地点（充电器）？当扫地机器人电量不足时，如何以最短的路径到达充电器所在位置进行自动充电。对应的术语叫：<em>路径规划（Route Planning）</em>。</p>
<p>有了以上的几个能力，扫地机器人就立马变的智能了，不再像无头苍蝇一样在室内乱跑，而是可以从任意位置出发，一边清扫一边对周围的环境（房屋结构、障碍物）建立地图，同时根据地图定位自己当前在地图中的位置，并实时调整规划路线。随着使用时间的增长，扫地机器人建立的地图会越来越准确，规划的清扫路线越来越高效，变的越来越智能。这也不难理解断点续扫（一次扫不完，回到充电地点重合点，回到原位置继续清扫）的功能是如何实现的了。</p>
<p>看明白了上面的例子，我们给出SLAM的定义。<em>SLAM是指当某种移动设备（如机器人）从一个未知环境里的未知地点出发，在运动过程中通过传感器观测定位自身位置、姿态、运动轨迹，再根据自身位置进行增量式的地图构建，从而达到同时定位和地图构建的目的。</em>定位和建图是两个相辅相成的过程，地图可以提供更好的定位，而定位也可以进一步扩建地图。SLAM非常强调未知环境，是自主移动机器人的核心技术。</p>
<h1 id="操作性定义"><a href="#操作性定义" class="headerlink" title="操作性定义"></a>操作性定义</h1><p>这里说的地图，是用来在环境中定位，以及描述当前环境以便于规划航线的一个概念；它通过记录以某种形式的感知获取的信息，用以和当前的感知结果相比较，以支撑对现实定位的评估。地图通常反映了它被描绘出来的时刻的环境状态，所以它并不一定反映它被使用的时刻的环境状态。</p>
<p>即时定位与地图构建（SLAM）是这样一个概念：把两方面的进程都捆绑在一个循环之中，以此支持双方在各自进程中都求得连续解；不同进程中相互迭代的反馈对双方的连续解有改进作用。</p>
<p>地图构建，是研究如何把从一系列传感器收集到的信息，集成到一个一致性的模型上的问题。它可以被描述为第一核心问题：这个世界长什么样？地图构建的核心部分是环境的表达方式以及传感器数据的解释。</p>
<p>与之相比，定位，是在地图上估测机器人的坐标和姿势形态的问题；换而言之，机器人需要回答这里的第二核心问题，我在哪？典型的解包含以下两个方面：追踪——通常机器人的初始位置已知；全局定位——通常只给出很少，甚至不给出有关于起始位置环境特征的先验信息。</p>
<p>所以，同步定位与地图构建（SLAM）被定义为以下问题：<strong>在建立新地图模型或者改进已知地图的同时，在该地图模型上定位机器人。</strong>实际上，这两个核心问题如果分开解决，将毫无意义；必须同时求解。</p>
<h1 id="技术上的问题"><a href="#技术上的问题" class="headerlink" title="技术上的问题"></a>技术上的问题</h1><p>同步定位与地图构建（SLAM）可以被看做是一个鸡生蛋蛋生鸡的问题：完美的定位需要用到一个无偏差的地图；但这样的地图又需要精确的位置估测来描绘。</p>
<ol>
<li>一般来说，由于技术环境中总会考虑噪声，所以SLAM方法要考虑的不只是数学上的紧凑解，也包括与那些和结果相关的物理概念的相互作用。2. 如果在地图构建的下一个迭代步骤中，测得的距离和方向有可预知的一系列不精确度——通常由传感器有限的的精确度和外加的环境噪声所引起，那么附加到地图上的所有特征都将会含有相应的误差。随着时间的推移和运动的变化，定位和地图构建的误差累计增加，将会对地图本身和机器人的定位、导航等能力的精度产生很大的扭曲。</li>
</ol>
<h2 id="地图构建"><a href="#地图构建" class="headerlink" title="地图构建"></a>地图构建</h2><p>在实用中，SLAM通常要被剪裁至适应可获得的资源，于是可以看出它的目标不是完美，而是操作实用性。已经发布的SLAM方法已被应用于无人机、无人潜艇、行星探测车、最近大热的家政机器人、甚至人体内部。</p>
<p>学界大致都认为，SLAM问题的“正在得到解决”是过去十年间机器人研究领域的最重大成果之一。该领域中仍有许多有待解决的难题，比如图像匹配和计算复杂度等方面的相关问题。</p>
<h1 id="SLAM传感器"><a href="#SLAM传感器" class="headerlink" title="SLAM传感器"></a>SLAM传感器</h1><p>SLAM的实现方式与难度和传感器的形式与安装方式密切相关。用于SLAM的传感器主要分为激光雷达和视觉两大类。</p>
<h2 id="激光雷达"><a href="#激光雷达" class="headerlink" title="激光雷达"></a>激光雷达</h2><p>激光雷达是非常传统的SLAM传感器。<em>它可以提供机器人本身与周围环境障碍物间的距离信息。</em>常见的激光雷达有SICK、Velodyne、Rplidar等。</p>
<p><img src="/2018/06/30/SLAM/jgld.webp" alt=""></p>
<p>主流的<em>2D激光传感器扫描一个平面内的障碍物，适用于平面运动的机器人（如扫地机等）进行定位，并建立2D的栅格地图。</em>这种地图在机器人导航中很实用，因为多数机器人还不能在空中飞行或走上台阶，仍限于地面。</p>
<p>在SLAM研究史上，<em>早期SLAM研究几乎全使用激光传感器进行建图，且多数使用滤波器方法，例如卡尔曼滤波器与粒子滤波器等。</em></p>
<p>激光雷达的技术方案有如下几个特点：</p>
<ol>
<li><em>精度很高，也比较稳定</em></li>
<li><em>速度快</em>，计算量也不大，容易做成实时SLAM</li>
<li><em>理论研究成熟</em>，激光雷达用于SLAM的技术方案（EKF-SLAM）因为研究较早，现在已经非常成熟。当然人们也对EKF-SLAM的缺点也有较清楚的认识，例如不易表示回环、线性化误差严重、必须维护路标点的协方差矩阵等。</li>
<li><em>笨重</em></li>
<li><em>价格昂贵</em>，激光雷达成本很高，因此激光的研究主要集中于如何降低传感器的成本上，现在激光雷达也有平价的产品了，现在高级的扫地机器人中就已经在使用激光雷达了，但性能配置会低一些</li>
</ol>
<h2 id="视觉传感器"><a href="#视觉传感器" class="headerlink" title="视觉传感器"></a>视觉传感器</h2><p>视觉传感器是近几年SLAM研究热点之一，特点：</p>
<ol>
<li><em>价格便宜</em></li>
<li><em>体积小，重量轻</em></li>
<li>可以获取<em>丰富且直观的信息</em>，有研究表明，视觉信息占了人类获取信息的80%以上，所以通过摄像头可以获取的信息要远远超过通过激光雷达获得的信息。</li>
<li><em>计算量大</em>，往往信息量和计算量是成正比的，视觉SLAM中的特征点检测、匹配等过程非常耗时。不过随着CPU、GPU处理器速度的飞速发展，很多以前被认为无法实时化的视觉算法，得以近乎实时化地运行。</li>
<li>需要一定的假设条件。比如视觉算法<em>无法在无纹理区域进行</em>。</li>
</ol>
<p><em>视觉SLAM传感器主要分为三大类：单目、双目（或多目）、RGBD。</em>此外还有鱼眼、全景等特殊相机，由于在研究和产品中都属于少数在此不做介绍。</p>
<p>就实现难度而言，这三类方法难易程度从难到易依次为：单目视觉、双目视觉、RGBD。下面来具体介绍。</p>
<p><img src="/2018/06/30/SLAM/mono.webp" alt=""></p>
<p>单目相机SLAM简称MonoSLAM，即只用一个摄像头实现SLAM。<em>优势是传感器特别的简单、成本特别的低，所以单目SLAM非常受研究者关注。</em></p>
<p><em>相比别的视觉传感器，单目有个最大的问题，就是没法确切地得到深度。</em></p>
<p>单目相机有如下几个特点：</p>
<ol>
<li><em>单目SLAM只能估计一个相对深度。</em>由于绝对深度未知，单目SLAM没法得到机器人运动轨迹以及地图的真实大小。直观地说，如果把轨迹和房间同时放大两倍，单目看到的像是一样的。</li>
<li>单目相机<em>必须通过运动</em>才能获取深度。它无法仅根据一张图像获得图像中物体离自己的相对距离。为了估计这个相对深度，单目SLAM要靠运动中的三角测量，来求解相机运动并估计像素的空间位置。也就是说，它的轨迹和地图，只有在相机运动之后才能收敛，如果相机不进行运动时，就无法得知像素的位置。</li>
<li>相机必须进行旋转和平移。相机运动还不能是纯粹的旋转，这就给单目SLAM的应用带来了一些麻烦，好在日常使用SLAM时，相机都会发生旋转和平移。</li>
<li>既可以用于室内，又可以用于室外。</li>
</ol>
<p><img src="/2018/06/30/SLAM/bino.webp" alt=""></p>
<p>与单目不同的是，双目立体视觉既可以在运动时估计深度，也可在静止时估计，消除了单目视觉的许多麻烦。不过，<em>双目或多目相机配置与标定均较为复杂，其深度量程也受双目的基线与分辨率限制。</em>此外，通过双目图像<em>计算深度计算量也非常大</em>。</p>
<p><img src="/2018/06/30/SLAM/rgbd.webp" alt=""></p>
<p>RGBD相机是一种可以获得彩色图并测量深度的相机。目前常用的RGBD相机包括Kinect一代、Kinect 二代、Xtion、Realsense等。RGBD相机有如下特点：</p>
<ol>
<li>一般通过结构光或Time-of-Flight原理，直接测出物体离摄像头的距离。相对于双目立体视觉，它的速度非常快，可以用于实时应用。</li>
<li>它比单目或双目相机能够提供更丰富的信息。</li>
<li>现在多数RGBD相机还存在视场角小、分辨率低等诸多问题。<em>主要用于室内SLAM</em>。</li>
</ol>
<h1 id="SLAM技术框架"><a href="#SLAM技术框架" class="headerlink" title="SLAM技术框架"></a>SLAM技术框架</h1><p><em>GPS只能在室外使用！而要想解决建筑物内、洞穴、海底等在GPS失效地域的定位、建图、姿态估计、路径规划，目前最有效的就是SLAM技术。</em></p>
<p>最早的SLAM雏形是在军事（核潜艇的海底定位）上的应用，主要传感器是军用雷达。SLAM技术发展到如今已经几十年，目前以激光雷达作为主传感器的SLAM技术比较稳定、可靠，仍然是主流的技术方案。但随着最近几年计算机视觉技术的快速发展，SLAM技术越来越多的应用于家用机器人、无人机、AR设备，基于视觉的Visual SLAM（简称VSLAM）逐渐开始崭露头角。</p>
<h2 id="VSLAM技术架构"><a href="#VSLAM技术架构" class="headerlink" title="VSLAM技术架构"></a>VSLAM技术架构</h2><p>本文主要介绍目前非常热门的VSLAM的技术框架，未来会有非常好的前景。VSLAM的技术框架如下，主要包括传感器数据预处理、前端、后端、回环检测、建图。</p>
<p><img src="/2018/06/30/SLAM/vslam1.webp" alt=""><br><img src="/2018/06/30/SLAM/vslam2.webp" alt=""></p>
  
	</div>
		<footer class="article-footer clearfix">

  <div class="article-tags">
  
  <span></span> <a href="/tags/SLAM/">SLAM</a>
  </div>




<div class="article-share" id="share">

  <div data-url="https://www.lijn.tech/2018/06/30/SLAM/" data-title="SLAM(Simultaneous localization and mapping) | LI jianan&#39;s Blog" data-tsina="" class="share clearfix">
  </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2018/07/03/imageprocess/" title="数字图像处理">
  <strong>Previous:</strong><br/>
  <span>
  数字图像处理</span>
</a>
</div>


<div class="next">
<a href="/2018/06/25/photo/"  title="拍照的姿势、技巧等等">
 <strong>Next:</strong><br/> 
 <span>拍照的姿势、技巧等等
</span>
</a>
</div>

</nav>

	

</div>  
    </div>
    <footer><div id="footer" >
	<div class="copyright">
		<span> If you are interested in Computer Vision, you can contact </span>
			<span> <a href="https://github.com/JnanLi">me.</a> </span>
	<div>
</div></footer>
    <script src="/js/jquery-2.1.0.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  //back to top
  function backToTop(){
    var buttonHTML = $("<a href=\"#top\" id=\"back-top\">" + "<span>Back to Top</span></a>");
    buttonHTML.appendTo($("body"));
    var buttonToTop = $("#back-top");
    // hide #back-top first
    buttonToTop.hide();

    // fade in #back-top
    $(function() {
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                buttonToTop.fadeIn();
            } else {
                buttonToTop.fadeOut();
            }
        });
        // scroll body to 0px on click
        buttonToTop.click(function() {
            $('body,html').animate({
                scrollTop: 0
            }, 800);
            return false;
        });
    });
  }
  backToTop();

  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      ta = $('#toc.toc-aside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
        
    }
  });

  var show = true;
  c.click(function(){
    if(show == true){
        a.addClass('fadeOut').css('display', 'none');
        ta.css('display', 'block').addClass('fadeIn');
        m.addClass('moveMain');  
    }else{
        a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');     
        ta.css('display', 'none'); 
        m.removeClass('moveMain');
        $('#toc.toc-aside').css('display', 'none');
    }
    show = !show;
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{

    $(window).scroll(function(){
      ta.css("top",Math.max(140,240-$(this).scrollTop()));
    });
  };
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#share"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="#textlogo" class="article-back-to-top" title="Top"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="QRcode"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="Weibo"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>




<script type="text/javascript">
  function footerPosition() {
    var contentHeight = document.documentElement.scrollHeight,
        winHeight = window.innerHeight;
    if(contentHeight <= winHeight) {
      $('footer').addClass('fixed-bottom');
    } else {
      $('footer').removeClass('fixed-bottom');
    }
  }
  footerPosition();
  $(window).resize(footerPosition);
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


  </body>
</html>
